{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb638b74",
   "metadata": {},
   "source": [
    "# Statisitcs and Research methods\n",
    "\n",
    "## Understanding Statistical Models vs. Machine Learning Models\n",
    "\n",
    "It's essential first to understand the distinctions between statistical models and machine learning models, as they serve different purposes, assumptions, and interpretative depth.\n",
    "\n",
    "- Statistical Models: \n",
    "    - These are rooted in traditional statistics and \n",
    "        - focus on relationships between variables through predefined equations. \n",
    "    - Statistical models aim to understand the underlying data-generating process, focusing on hypothesis testing and inference. \n",
    "    - These models often rely on strong assumptions like:\n",
    "        - linearity, \n",
    "        - normality, and \n",
    "        - homoscedasticity \n",
    "        - and are **interpretable**, making it easier to understand the impact of individual variables.\n",
    "\n",
    "- Machine Learning Models: \n",
    "    - These prioritize **predictive** power over interpretability. \n",
    "    - They are designed to automatically learn patterns and relationships within data, often with minimal assumptions. \n",
    "    - Machine learning models can handle complex and high-dimensional data but may lack transparency about how individual features affect the outcome, especially in “black box” models like neural networks or ensemble methods.\n",
    "\n",
    "\n",
    "## Choosing the Right Statistical Model\n",
    "\n",
    "The type of statistical model you use depends on your data and problem:\n",
    "\n",
    "- Linear Regression: For predicting a **continuous target variable** based on one or more predictors.\n",
    "- Logistic Regression: For predicting a **binary outcomes**, often used in classification problems.\n",
    "- ANOVA (Analysis of Variance): For comparing means across multiple groups.\n",
    "- Time Series Models: For data that’s ordered by time (e.g., ARIMA, SARIMA).\n",
    "- Survival Analysis: For time-to-event data, such as customer churn timing.\n",
    "- Multivariate Analysis: For understanding interactions across multiple variables (e.g., MANOVA, PCA).\n",
    "\n",
    "## Preprocessing the Data\n",
    "Prepare your data by cleaning and preprocessing it:\n",
    "\n",
    "- Missing Values: Decide whether to impute or drop missing values.\n",
    "- Outliers: Identify and consider handling outliers, especially in regression.\n",
    "- Data Transformation: Transform non-normal variables if required (e.g., using log transformations).\n",
    "- Feature Scaling: For some models, standardizing or normalizing data is essential.\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA is essential to understand: \n",
    "- patterns,\n",
    "    - visualizations\n",
    "- distributions,\n",
    "    - summary statistics\n",
    "- relationships\n",
    "    - correlation matrices\n",
    "    \n",
    "This is to identify relevant features and spot potential issues like multicollinearity.\n",
    "\n",
    "## Building the Statistical Model\n",
    "\n",
    "- **Statsmodels** provides \n",
    "    - coefficients, \n",
    "    - p-values, and \n",
    "    - confidence intervals for each variable, \n",
    "        - enabling hypothesis testing on whether each predictor significantly affects the outcome.\n",
    "\n",
    "## Evaluating Model Performance\n",
    "Regression Metrics: \n",
    "- Use R-squared, \n",
    "- Adjusted R-squared, \n",
    "- RMSE, and \n",
    "- MAE to evaluate regression models.\n",
    "\n",
    "Classification Metrics: \n",
    "- Use confusion matrix, \n",
    "- accuracy, \n",
    "- precision, \n",
    "- recall, and \n",
    "- AUC-ROC.\n",
    "\n",
    "Residual Analysis: \n",
    "- Residual plots help assess assumptions\n",
    "    - homoscedasticity, \n",
    "    - normality of residuals).\n",
    "\n",
    "## Model Interpretation\n",
    "Statistical models are highly interpretable. \n",
    "- In linear regression, each coefficient represents the expected change in the dependent variable for a one-unit change in the predictor, holding all else constant.\n",
    "\n",
    "Confidence Intervals: \n",
    "- Look at 95% CI for each coefficient; if it does not contain zero, it suggests the predictor has a statistically significant effect.\n",
    "\n",
    "P-Values: \n",
    "- A p-value below a threshold (usually 0.05) indicates that the predictor significantly affects the outcome.\n",
    "\n",
    "## Validating Assumptions\n",
    "- Linearity: Check scatter plots of residuals.\n",
    "- Normality of Residuals: Use a Q-Q plot to verify.\n",
    "- No Multicollinearity: Variance inflation factor (VIF) helps detect multicollinearity.\n",
    "- Homoscedasticity: Plot residuals vs. fitted values.\n",
    "\n",
    "## Reporting and Communicating Results\n",
    "Present your findings by focusing on:\n",
    "\n",
    "- Key Coefficients: Explain which predictors significantly affect the outcome.\n",
    "- Model Fit: Interpret R-squared values (e.g., explaining how much variance in the target variable is explained).\n",
    "- Real-World Implications: Describe how insights from the model can impact business decisions.\n",
    "\n",
    "# Approach to statistical modeling\n",
    "\n",
    "Each model type has specific \n",
    "- applications, \n",
    "- strengths, and \n",
    "- limitations, \n",
    "\n",
    "Understand when and how to use them.\n",
    "\n",
    "### Step 1: Define Objectives and Hypotheses\n",
    "\n",
    "Identify the Problem and Objectives: \n",
    "- Clearly define the goal.\n",
    "    - Are you trying to predict, classify, find patterns, or estimate relationships? \n",
    "    - Setting objectives helps in choosing the right model.\n",
    "\n",
    "- Formulate Hypotheses: \n",
    "    - Based on the problem, develop hypotheses. \n",
    "        - For instance, in a sales prediction problem, you may hypothesize that `certain features like advertising spend, time of year, and economic indicators affect sales.`\n",
    "\n",
    "### Step 2: Data Collection and Preprocessing\n",
    "Data Collection: \n",
    "- Gather historical data related to the problem. \n",
    "\n",
    "Data Cleaning: \n",
    "- Handle missing values, remove duplicates, and ensure consistency.\n",
    "\n",
    "Feature Engineering: \n",
    "- Create new features if necessary. \n",
    "- This could involve \n",
    "    - transformations, \n",
    "    - encoding categorical variables, or \n",
    "    - creating interaction terms.\n",
    "\n",
    "Data Splitting: \n",
    "- Split the data into training and testing sets. Typically, an 80-20 or 70-30 split is used.\n",
    "\n",
    "### Step 3: Select the Type of Statistical Model\n",
    "Statistical models can be broadly categorized as:\n",
    "\n",
    "- **Descriptive Models**: Summarize data patterns.\n",
    "- **Inferential Models**: Help make inferences about the population.\n",
    "- **Predictive Models**: Used to predict future outcomes based on historical data.\n",
    "- **Prescriptive Models**: Suggest actions based on predictions.\n",
    "\n",
    "Let's go through common types of statistical models and their applications.\n",
    "\n",
    "\n",
    "# Regression Analysis\n",
    " \n",
    "Regression Analysis is a statistical method to analyze the relationship between a dependent variable and one or more independent variables.\n",
    "\n",
    "### Three types of regression analysis\n",
    "\n",
    "##### Real-world examples\n",
    "- Simple linear regression\n",
    "    - A real estate agent wants to determine the relationship between the size of a house (in square feet) and its selling price. They can use simple linear regression to predict the selling price of a house based on its size.\n",
    "    \n",
    "-  Multiple Linear Regression\n",
    "    - A car manufacturer wants to predict the fuel efficiency of their vehicles based on various independent variables such as engine size, horsepower, and weight.\n",
    "    \n",
    "- Logistic regression\n",
    "    - A bank wants to predict whether a customer will default on their loan based on their credit score, income, and other factors. By using logistic regression, the bank can estimate the probability of default and take appropriate measures to minimize their risk.\n",
    "\n",
    "##### 1. Linear Regression\n",
    "\n",
    "What It Means: \n",
    "- Linear regression models the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data. It assumes a straight-line relationship. \n",
    "\n",
    "- It is employed to establish a link between a dependant variable and a single independent variable. \n",
    "    - A linear equation defines the relationship, with the \n",
    "        - slope and \n",
    "        - intercept \n",
    "    - of the line representing the effect of the independent variable on the dependant variable.\n",
    "\n",
    "Outcome Interpretation: \n",
    "- Each coefficient represents how much the dependent variable (outcome) changes when the predictor variable changes by one unit, keeping all else constant.\n",
    "\n",
    "Performance Measures:\n",
    "- R-squared: Indicates the proportion of the variance in the dependent variable explained by the independent variables. \n",
    "    - Values closer to 1 indicate a better fit.\n",
    "- Mean Squared Error (MSE): The average squared difference between observed and predicted values; lower values are better.\n",
    "\n",
    "Lay Explanation: \n",
    "- Think of linear regression like drawing a best-fit line through a scatterplot of data points, aiming to predict outcomes based on relationships in the data.\n",
    "\n",
    "Use Case: \n",
    "- When there is a linear relationship between the target and predictor variables.\n",
    "\n",
    "Model Equation:\n",
    "$ 𝑦=𝛽_{0}+𝛽_{1}𝑥_{1}+…+𝛽_{𝑛}𝑥_{𝑛}+ 𝜖 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ff6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create the dataset\n",
    "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\n",
    "y = np.array([2, 4, 5, 7, 8, 10, 11, 13, 14, 16])\n",
    "\n",
    "# Create the linear regression model\n",
    "model = LinearRegression().fit(X, y)\n",
    "\n",
    "# Get the slope and intercept of the line\n",
    "slope = model.coef_\n",
    "intercept = model.intercept_\n",
    "\n",
    "# Plot the data points and the regression line\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, slope*X + intercept, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123f51a4",
   "metadata": {},
   "source": [
    "##### Multiple Linear Regression:\n",
    "\n",
    "What it means:\n",
    "- It is used when two or more independent variables influence the dependant variable. \n",
    "\n",
    "- A linear equation defines the relationship, with the \n",
    "    - coefficients of the independent variables \n",
    "    \n",
    "- representing the effect of each variable on the dependant variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb634e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "data = pd.read_csv('data.csv') # read data from csv file\n",
    "X = data[['Independent_Var_1', 'Independent_Var_2', 'Independent_Var_3']] # select independent variables\n",
    "Y = data['Dependent_Var'] # select dependent variable\n",
    "\n",
    "# Add a constant to the independent variable set\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the logistic regression model\n",
    "model = sm.Logit(Y, X).fit()\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6228e",
   "metadata": {},
   "source": [
    "\n",
    "##### 2. Logistic Regression\n",
    "What It Means: \n",
    "- Logistic regression estimates the probability of a binary outcome (e.g., yes/no, success/failure) based on predictor variables. \n",
    "    - It uses a logistic function to map predictions to probabilities between 0 and 1.\n",
    "\n",
    "- It is a statistical technique for investigating the relationship between a binary dependent variable (outcome) and one or more independent variables (predictors). \n",
    "\n",
    "- The goal of logistic regression is to find the best-fitting model to describe the relationship between the dependent variable and the independent variables and then use that model to predict the outcome variable.\n",
    "\n",
    "Outcome Interpretation: \n",
    "- The model outputs probabilities that can be converted to binary outcomes. \n",
    "- Coefficients show how each predictor variable influences the likelihood of the outcome.\n",
    "\n",
    "Performance Measures:\n",
    "- Accuracy: Proportion of correct predictions.\n",
    "- AUC-ROC: Measures the model's ability to distinguish between classes; values closer to 1 indicate a better model.\n",
    "\n",
    "Lay Explanation: \n",
    "- Logistic regression is like a yes-or-no decision helper. It estimates the chances of an event happening (e.g., a customer buying a product) based on known factors.\n",
    "\n",
    "Use Case: Used for binary classification (e.g., churn prediction, fraud detection).\n",
    "\n",
    "Model Equation: \n",
    "$ 𝑃(𝑦=1)= \\frac{1}{1+𝑒^{−(𝛽_{0}+𝛽_{1}𝑥_{1}+…+𝛽_{𝑛}𝑥_{𝑛}})}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3daca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train = data[:800]\n",
    "test = data[800:]\n",
    "\n",
    "# Define the independent variables\n",
    "X_train = train[['age', 'gender', 'income']]\n",
    "X_test = test[['age', 'gender', 'income']]\n",
    "\n",
    "# Define the dependent variable\n",
    "y_train = train['buy_product']\n",
    "y_test = test['buy_product']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict the outcomes for the test data\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b8436",
   "metadata": {},
   "source": [
    "##### 3. Generalized Linear Models (GLMs)\n",
    "What It Means: \n",
    "- GLMs extend linear regression by allowing different types of data distributions\n",
    "    - Poisson for count data. \n",
    "- It models the mean of the outcome variable based on a link function.\n",
    "\n",
    "Outcome Interpretation: \n",
    "- The coefficients explain how each predictor affects the mean outcome, given the distribution.\n",
    "\n",
    "Performance Measures:\n",
    "- Deviance: Measures how well the model fits compared to a perfect model; lower values are better.\n",
    "\n",
    "Lay Explanation: \n",
    "- GLMs are like flexible versions of linear regression that can handle different data types (like counts or binary data), giving predictions that respect the data’s nature.\n",
    "\n",
    "Use Case: \n",
    "- Extends linear regression for non-normal distributions (e.g., Poisson regression for count data).\n",
    "\n",
    "Model Types: \n",
    "- Poisson regression, \n",
    "- Binomial regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48888f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "poisson_model = sm.GLM(y_train, X_train, family=sm.families.Poisson()).fit()\n",
    "predictions = poisson_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af5a09e",
   "metadata": {},
   "source": [
    "##### 4. Time Series Models (e.g., ARIMA)\n",
    "What It Means: \n",
    "- Time series models account for:\n",
    "    - trends, \n",
    "    - seasonality, and \n",
    "    - temporal dependencies in data collected over time, often used for forecasting future values.\n",
    "\n",
    "Outcome Interpretation: \n",
    "- Each prediction is based on patterns in past data points, accounting for recent trends and cycles.\n",
    "\n",
    "Performance Measures:\n",
    "- Mean Absolute Percentage Error (MAPE): Shows the average prediction error in percentage terms.\n",
    "- Root Mean Squared Error (RMSE): Measures the prediction accuracy; lower values mean better predictions.\n",
    "\n",
    "Lay Explanation: \n",
    "- Time series models are like weather forecasts—they predict future values based on past patterns, like trends and cycles.\n",
    "\n",
    "Use Case: \n",
    "- Forecasting for data with a temporal component (e.g., sales data, stock prices).\n",
    "\n",
    "Model Types: \n",
    "- ARIMA, \n",
    "- SARIMA, \n",
    "- Exponential Smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce38a9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "model = ARIMA(time_series_data, order=(1,1,1))\n",
    "model_fit = model.fit()\n",
    "predictions = model_fit.forecast(steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f3ef82",
   "metadata": {},
   "source": [
    "##### 5. Decision Trees and Random Forests\n",
    "What It Means: \n",
    "- Decision trees split data based on conditions, creating branches that lead to a prediction. \n",
    "- Random forests use multiple trees to improve accuracy and reduce overfitting.\n",
    "\n",
    "Outcome Interpretation: \n",
    "- Each \"branch\" shows how different conditions affect the outcome, \n",
    "- and random forests average the results of many trees for robust predictions.\n",
    "\n",
    "Performance Measures:\n",
    "- Accuracy: Proportion of correctly classified samples.\n",
    "- Gini Index / Entropy: Used to measure the purity of the splits; lower values are better.\n",
    "\n",
    "Lay Explanation: \n",
    "- Decision trees are like flowcharts that guide predictions based on conditions. \n",
    "- Random forests combine many trees to make stronger, more reliable decisions.\n",
    "\n",
    "Use Case: \n",
    "- For classification or regression problems with non-linear relationships and high dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63e3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, y_train)\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "predictions_tree = tree_model.predict(X_test)\n",
    "predictions_rf = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f382cd",
   "metadata": {},
   "source": [
    "##### 6. Support Vector Machines (SVM)\n",
    "What It Means: \n",
    "- SVMs classify data by finding the best “boundary” (hyperplane) that separates classes with the widest possible margin.\n",
    "\n",
    "Outcome Interpretation: \n",
    "- Data points on either side of the boundary belong to different classes, with \"support vectors\" helping to define the boundary.\n",
    "\n",
    "Performance Measures:\n",
    "- Accuracy: Proportion of correct classifications.\n",
    "- Precision and Recall: Used when classes are imbalanced; precision is the correctness of positive predictions, and recall measures coverage.\n",
    "\n",
    "Lay Explanation: \n",
    "- SVMs are like drawing a line to separate different groups, ensuring the groups are as distinct as possible with the help of a few key points.\n",
    "\n",
    "Use Case: \n",
    "- Used for classification and regression in high-dimensional spaces, often for non-linearly separable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25b8cd",
   "metadata": {},
   "source": [
    "##### 7. Clustering Models (e.g., K-Means)\n",
    "What It Means: \n",
    "- Clustering groups similar data points together without predefined labels, often used for segmenting customers or finding patterns.\n",
    "\n",
    "Outcome Interpretation: \n",
    "- Each cluster represents a natural grouping in the data, with data points in the same cluster sharing similar characteristics.\n",
    "\n",
    "Performance Measures:\n",
    "- Silhouette Score: Measures how well each point fits within its cluster; values closer to 1 indicate better-defined clusters.\n",
    "- Within-Cluster Sum of Squares (WCSS): Measures the compactness of clusters; lower values are better.\n",
    "\n",
    "Lay Explanation: \n",
    "- Clustering is like sorting items into bins based on similarity, helping us identify groups in our data.\n",
    "\n",
    "Use Case: \n",
    "- To group similar observations without predefined labels.\n",
    "\n",
    "Model Types: \n",
    "- K-Means, \n",
    "- Hierarchical Clustering, \n",
    "- DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3cfc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea1408",
   "metadata": {},
   "source": [
    "##### 8. Principal Component Analysis (PCA)\n",
    "What It Means: \n",
    "- PCA reduces the number of variables in the data by finding combinations of variables that capture the most information (variance).\n",
    "\n",
    "Outcome Interpretation: \n",
    "- Each \"principal component\" explains a percentage of the total variance, helping simplify the data without losing much information.\n",
    "\n",
    "Performance Measures:\n",
    "- Explained Variance Ratio: Shows how much information each principal component holds; higher is better.\n",
    "\n",
    "Lay Explanation: \n",
    "- PCA is like summarizing a book by keeping only the most important points, making data easier to work with without losing key insights.\n",
    "\n",
    "Use Case: \n",
    "- Dimensionality reduction while retaining the most critical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23bf1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d6d396",
   "metadata": {},
   "source": [
    "##### 9. Bayesian Models\n",
    "What It Means: \n",
    "- Bayesian models incorporate prior knowledge or beliefs with the data to update the probability of outcomes as new evidence is available.\n",
    "\n",
    "Outcome Interpretation: \n",
    "- Each output is a probability distribution reflecting both prior knowledge and the new data, offering a range of likely outcomes.\n",
    "\n",
    "Performance Measures:\n",
    "- Log-Likelihood: Measures how well the model explains the data; higher values indicate better fit.\n",
    "\n",
    "Lay Explanation: \n",
    "- Bayesian models are like revising a guess based on new evidence—updating beliefs as we get more information.\n",
    "\n",
    "Use Case: \n",
    "- To incorporate prior knowledge and quantify uncertainty.\n",
    "\n",
    "Model Types: \n",
    "- Bayesian Linear Regression, \n",
    "- Bayesian Networks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6500107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "with pm.Model() as model:\n",
    "    alpha = pm.Normal('alpha', mu=0, sigma=1)\n",
    "    beta = pm.Normal('beta', mu=0, sigma=1, shape=len(X_train.columns))\n",
    "    epsilon = pm.HalfNormal('epsilon', sigma=1)\n",
    "    mu = alpha + pm.math.dot(X_train, beta)\n",
    "    y_pred = pm.Normal('y_pred', mu=mu, sigma=epsilon, observed=y_train)\n",
    "    trace = pm.sample(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac011c6c",
   "metadata": {},
   "source": [
    "##### 10. Survival Analysis (e.g., Cox Proportional Hazards)\n",
    "What It Means: \n",
    "- Survival analysis predicts the time until an event occurs, such as customer churn or equipment failure.\n",
    "\n",
    "Outcome Interpretation: \n",
    "- Each output shows the likelihood of the event happening over time, considering various risk factors.\n",
    "\n",
    "Performance Measures:\n",
    "- Concordance Index (C-Index): Measures the model’s ability to correctly rank predictions; values closer to 1 indicate better performance.\n",
    "\n",
    "Lay Explanation: \n",
    "Survival analysis is like tracking how long something will last, based on factors that might speed it up or slow it down.\n",
    "\n",
    "Use Case: \n",
    "- For time-to-event data, such as time until a customer churns or equipment fails.\n",
    "\n",
    "Model Types: \n",
    "- Kaplan-Meier estimator, Cox Proportional Hazards Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995ebf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import CoxPHFitter\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(data, 'time', event_col='event')\n",
    "cph.predict_survival_function(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bc25f7",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf07849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to compute True Positives, True Negatives, False Positives and False Negatives\n",
    "\n",
    "def true_positive(y_true, y_pred):\n",
    "    tp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1\n",
    "    return tp\n",
    "\n",
    "def true_negative(y_true, y_pred):\n",
    "    tn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn += 1        \n",
    "    return tn\n",
    "\n",
    "def false_positive(y_true, y_pred):\n",
    "    fp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1       \n",
    "    return fp\n",
    "\n",
    "def false_negative(y_true, y_pred):\n",
    "    fn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1        \n",
    "    return fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea735dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix) \n",
    "FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "TP = np.diag(cnf_matrix)\n",
    "TN = cnf_matrix.sum() - (FP + FN + TP)FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "# Overall accuracy for each class\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf443ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation for table metrics:\n",
    "import sklearn.metrics\n",
    "import mathdef matrix_metrix(real_values,pred_values,beta):\n",
    "CM = confusion_matrix(real_values,pred_values)\n",
    "TN = CM[0][0]\n",
    "FN = CM[1][0] \n",
    "TP = CM[1][1]\n",
    "FP = CM[0][1]\n",
    "Population = TN+FN+TP+FP\n",
    "Prevalence = round( (TP+FP) / Population,2)\n",
    "Accuracy   = round( (TP+TN) / Population,4)\n",
    "Precision  = round( TP / (TP+FP),4 )\n",
    "NPV        = round( TN / (TN+FN),4 )\n",
    "FDR        = round( FP / (TP+FP),4 )\n",
    "FOR        = round( FN / (TN+FN),4 ) \n",
    "check_Pos  = Precision + FDR\n",
    "check_Neg  = NPV + FOR\n",
    "Recall     = round( TP / (TP+FN),4 )\n",
    "FPR        = round( FP / (TN+FP),4 )\n",
    "FNR        = round( FN / (TP+FN),4 )\n",
    "TNR        = round( TN / (TN+FP),4 ) \n",
    "check_Pos2 = Recall + FNR\n",
    "check_Neg2 = FPR + TNR\n",
    "LRPos      = round( Recall/FPR,4 ) \n",
    "LRNeg      = round( FNR / TNR ,4 )\n",
    "DOR        = round( LRPos/LRNeg)\n",
    "F1         = round ( 2 * ((Precision*Recall)/(Precision+Recall)),4)\n",
    "FBeta      = round ( (1+beta**2)*((Precision*Recall)/((beta**2 * Precision)+ Recall)) ,4)\n",
    "MCC        = round ( ((TP*TN)-(FP*FN))/math.sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))  ,4)\n",
    "BM         = Recall+TNR-1\n",
    "MK         = Precision+NPV-1   \n",
    "\n",
    "mat_met = pd.DataFrame({'Metric':['TP','TN','FP','FN','Prevalence','Accuracy','Precision','NPV','FDR','FOR','check_Pos','check_Neg','Recall','FPR','FNR','TNR','check_Pos2','check_Neg2','LR+','LR-','DOR','F1','FBeta','MCC','BM','MK'],     \n",
    "                        'Value':[TP,TN,FP,FN,Prevalence,Accuracy,Precision,NPV,FDR,FOR,check_Pos,check_Neg,Recall,FPR,FNR,TNR,check_Pos2,check_Neg2,LRPos,LRNeg,DOR,F1,FBeta,MCC,BM,MK]})   \n",
    "\n",
    "return (mat_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc1c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Implementation\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplotfpr, tpr, thresholds = roc_curve(real_values, prob_values)\n",
    "\n",
    "auc = roc_auc_score(real_values, prob_values)\n",
    "print('AUC: %.3f' % auc)pyplot.plot(fpr, tpr, linestyle='--', label='Roc curve')\n",
    "pyplot.xlabel('False Positive Rate')\n",
    "pyplot.ylabel('True Positive Rate')\n",
    "pyplot.legend()pyplot.show()\n",
    "\n",
    "# Precision-recall implementation\n",
    "\n",
    "precision, recall, thresholds = sklearn.metrics.precision_recall_curve(real_values,prob_values)pyplot.plot(recall, precision, linestyle='--', label='Precision versus Recall')\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "pyplot.legend()pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba51b0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for get many metrics directly from sklearn\n",
    "\n",
    "def sk_metrix(real_values,pred_values,beta):\n",
    "Accuracy = round( sklearn.metrics.accuracy_score(real_values,pred_values) ,4)\n",
    "Precision= round( sklearn.metrics.precision_score(real_values,pred_values),4 )\n",
    "Recall   = round( sklearn.metrics.recall_score(real_values,pred_values),4 )   \n",
    "F1       = round ( sklearn.metrics.f1_score(real_values,pred_values),4)\n",
    "FBeta    = round ( sklearn.metrics.fbeta_score(real_values,pred_values,beta) ,4)\n",
    "MCC      = round ( sklearn.metrics.matthews_corrcoef(real_values,pred_values)  ,4)   \n",
    "Hamming  = round ( sklearn.metrics.hamming_loss(real_values,pred_values) ,4)   \n",
    "Jaccard  = round ( sklearn.metrics.jaccard_score(real_values,pred_values) ,4)   \n",
    "Prec_Avg = round ( sklearn.metrics.average_precision_score(real_values,pred_values) ,4)   \n",
    "Accu_Avg = round ( sklearn.metrics.balanced_accuracy_score(real_values,pred_values) ,4)   \n",
    "\n",
    "mat_met = pd.DataFrame({\n",
    "'Metric': ['Accuracy','Precision','Recall','F1','FBeta','MCC','Hamming','Jaccard','Precision_Avg','Accuracy_Avg'],\n",
    "'Value': [Accuracy,Precision,Recall,F1,FBeta,MCC,Hamming,Jaccard,Prec_Avg,Accu_Avg]})   \n",
    "\n",
    "return (mat_met)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e097be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Metrics For Multi-class Classification\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to calculate accuracy\n",
    "    -> param y_true: list of true values\n",
    "    -> param y_pred: list of predicted values\n",
    "    -> return: accuracy score\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "# Intitializing variable to store count of correctly predicted classes\n",
    "    correct_predictions = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            correct_predictions += 1\n",
    "    #returns accuracy\n",
    "    return correct_predictions / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eeb9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of macro-averaged precision\n",
    "\n",
    "def macro_precision(y_true, y_pred):\n",
    "\n",
    "    # find the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "\n",
    "    # initialize precision to 0\n",
    "    precision = 0\n",
    "    \n",
    "    # loop over all classes\n",
    "    for class_ in list(y_true.unique()):\n",
    "        \n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        \n",
    "        # compute true positive for current class\n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        \n",
    "        # compute false positive for current class\n",
    "        fp = false_positive(temp_true, temp_pred)\n",
    "        \n",
    "        \n",
    "        # compute precision for current class\n",
    "        temp_precision = tp / (tp + fp + 1e-6)\n",
    "        # keep adding precision for all classes\n",
    "        precision += temp_precision\n",
    "        \n",
    "    # calculate and return average precision over all classes\n",
    "    precision /= num_classes\n",
    "    \n",
    "    return precision\n",
    "\n",
    "print(f\"Macro-averaged Precision score : {macro_precision(y_test, y_pred) }\")\n",
    "\n",
    "# implement marco-averaged precision using sklearn\n",
    "macro_averaged_precision = metrics.precision_score(y_test, y_pred, average = 'macro')\n",
    "print(f\"Macro-Averaged Precision score using sklearn library : {macro_averaged_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938c138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of micro-averaged precision\n",
    "\n",
    "def micro_precision(y_true, y_pred):\n",
    "\n",
    "\n",
    "    # find the number of classes \n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initialize tp and fp to 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    # loop over all classes\n",
    "    for class_ in y_true.unique():\n",
    "        \n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        # calculate true positive for current class\n",
    "        # and update overall tp\n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    "        \n",
    "        # calculate false positive for current class\n",
    "        # and update overall tp\n",
    "        fp += false_positive(temp_true, temp_pred)\n",
    "        \n",
    "    # calculate and return overall precision\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision\n",
    "\n",
    "print(f\"Micro-averaged Precision score : {micro_precision(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "#  implement mirco-averaged precision using sklearn\n",
    "micro_averaged_precision = metrics.precision_score(y_test, y_pred, average = 'micro')\n",
    "print(f\"Micro-Averaged Precision score using sklearn library : {micro_averaged_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ed0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of macro-averaged recall\n",
    "\n",
    "def macro_recall(y_true, y_pred):\n",
    "\n",
    "    # find the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "\n",
    "    # initialize recall to 0\n",
    "    recall = 0\n",
    "    \n",
    "    # loop over all classes\n",
    "    for class_ in list(y_true.unique()):\n",
    "        \n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        \n",
    "        # compute true positive for current class\n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        \n",
    "        # compute false negative for current class\n",
    "        fn = false_negative(temp_true, temp_pred)\n",
    "        \n",
    "        \n",
    "        # compute recall for current class\n",
    "        temp_recall = tp / (tp + fn + 1e-6)\n",
    "        \n",
    "        # keep adding recall for all classes\n",
    "        recall += temp_recall\n",
    "        \n",
    "    # calculate and return average recall over all classes\n",
    "    recall /= num_classes\n",
    "    \n",
    "    return recall\n",
    "\n",
    "print(f\"Macro-averaged recall score : {macro_recall(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "# implement macro-averaged recall using sklearn\n",
    "\n",
    "macro_averaged_recall = metrics.recall_score(y_test, y_pred, average = 'macro')\n",
    "print(f\"Macro-averaged recall score using sklearn : {macro_averaged_recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of micro-averaged recall\n",
    "\n",
    "def micro_recall(y_true, y_pred):\n",
    "\n",
    "\n",
    "    # find the number of classes \n",
    "    num_classes = len(np.unique(y_true))\n",
    "    \n",
    "    # initialize tp and fp to 0\n",
    "    tp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    # loop over all classes\n",
    "    for class_ in y_true.unique():\n",
    "        \n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        # calculate true positive for current class\n",
    "        # and update overall tp\n",
    "        tp += true_positive(temp_true, temp_pred)\n",
    "        \n",
    "        # calculate false negative for current class\n",
    "        # and update overall tp\n",
    "        fn += false_negative(temp_true, temp_pred)\n",
    "        \n",
    "    # calculate and return overall recall\n",
    "    recall = tp / (tp + fn)\n",
    "    return recall\n",
    "\n",
    "print(f\"Micro-averaged recall score : {micro_recall(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "#  implement micro-averaged recall using sklearn\n",
    "\n",
    "micro_averaged_recall = metrics.recall_score(y_test, y_pred, average = 'micro')\n",
    "print(f\"Micro-Averaged recall score using sklearn library : {micro_averaged_recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d50779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of macro-averaged f1 score\n",
    "\n",
    "def macro_f1(y_true, y_pred):\n",
    "\n",
    "    # find the number of classes\n",
    "    num_classes = len(np.unique(y_true))\n",
    "\n",
    "    # initialize f1 to 0\n",
    "    f1 = 0\n",
    "    \n",
    "    # loop over all classes\n",
    "    for class_ in list(y_true.unique()):\n",
    "        \n",
    "        # all classes except current are considered negative\n",
    "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
    "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
    "        \n",
    "        \n",
    "        # compute true positive for current class\n",
    "        tp = true_positive(temp_true, temp_pred)\n",
    "        \n",
    "        # compute false negative for current class\n",
    "        fn = false_negative(temp_true, temp_pred)\n",
    "        \n",
    "        # compute false positive for current class\n",
    "        fp = false_positive(temp_true, temp_pred)\n",
    "        \n",
    "        \n",
    "        # compute recall for current class\n",
    "        temp_recall = tp / (tp + fn + 1e-6)\n",
    "        \n",
    "        # compute precision for current class\n",
    "        temp_precision = tp / (tp + fp + 1e-6)\n",
    "        \n",
    "        \n",
    "        temp_f1 = 2 * temp_precision * temp_recall / (temp_precision + temp_recall + 1e-6)\n",
    "        \n",
    "        # keep adding f1 score for all classes\n",
    "        f1 += temp_f1\n",
    "        \n",
    "    # calculate and return average f1 score over all classes\n",
    "    f1 /= num_classes\n",
    "    \n",
    "    return f1\n",
    "\n",
    "\n",
    "print(f\"Macro-averaged f1 score : {macro_f1(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "# implement macro-averaged F1 score using sklearn\n",
    "\n",
    "macro_averaged_f1 = metrics.f1_score(y_test, y_pred, average = 'macro')\n",
    "print(f\"Macro-Averaged F1 score using sklearn library : {macro_averaged_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f53eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computation of micro-averaged fi score\n",
    "\n",
    "def micro_f1(y_true, y_pred):\n",
    "\n",
    "\n",
    "    #micro-averaged precision score\n",
    "    P = micro_precision(y_true, y_pred)\n",
    "\n",
    "    #micro-averaged recall score\n",
    "    R = micro_recall(y_true, y_pred)\n",
    "\n",
    "    #micro averaged f1 score\n",
    "    f1 = 2*P*R / (P + R)    \n",
    "\n",
    "    return f1\n",
    "\n",
    "print(f\"Micro-averaged recall score : {micro_f1(y_test, y_pred)}\")\n",
    "\n",
    "\n",
    "# implement micro-averaged F1 score using sklearn\n",
    "\n",
    "micro_averaged_f1 = metrics.f1_score(y_test, y_pred, average = 'micro')\n",
    "print(f\"Micro-Averaged F1 score using sklearn library : {micro_averaged_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe51cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUCurve Computation\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def roc_auc_score_multiclass(actual_class, pred_class, average = \"macro\"):\n",
    "    \n",
    "    #creating a set of all the unique classes using the actual class list\n",
    "    unique_class = set(actual_class)\n",
    "    roc_auc_dict = {}\n",
    "    for per_class in unique_class:\n",
    "        \n",
    "        #creating a list of all the classes except the current class \n",
    "        other_class = [x for x in unique_class if x != per_class]\n",
    "\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "        new_actual_class = [0 if x in other_class else 1 for x in actual_class]\n",
    "        new_pred_class = [0 if x in other_class else 1 for x in pred_class]\n",
    "\n",
    "        #using the sklearn metrics method to calculate the roc_auc_score\n",
    "        roc_auc = roc_auc_score(new_actual_class, new_pred_class, average = average)\n",
    "        roc_auc_dict[per_class] = roc_auc\n",
    "\n",
    "    return roc_auc_dict\n",
    "\n",
    "roc_auc_dict = roc_auc_score_multiclass(y_test, y_pred)\n",
    "roc_auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a3d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC implementation: \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Load the iris data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target# Binarize the output\n",
    "y_bin = label_binarize(y, classes=[0, 1, 2])\n",
    "n_classes = y_bin.shape[1]# We split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size= 0.5, random_state=0)\n",
    "\n",
    "\n",
    "# We define the model as an SVC in OneVsRestClassifier setting.\n",
    "# this means that the model will be used for class 1 vs class 2, \n",
    "# class 2vs class 3 and class 1 vs class 3. \n",
    "# So, we have 3 cases at #the end and within each case, the bias will be varied in order to \n",
    "# Get the ROC curve of the given case - 3 ROC curves as output.\n",
    "\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True, random_state=0))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "# Plotting and estimation of FPR, TPR\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "colors = cycle(['blue', 'red', 'green'])\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=1.5, label='ROC curve of class {0} (area = {1:0.2f})' ''.format(i+1, roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], 'k-', lw=1.5)\n",
    "    plt.xlim([-0.05, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic for multi-class data')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69585b42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
